{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-y594x601w_x"},"outputs":[],"source":["import traitlets\n","import ipywidgets.widgets as widgets\n","from IPython.display import display\n","from jetbot import Camera, bgr8_to_jpeg\n","\n","camera = Camera.instance(width=224, height=224)\n","\n","image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n","\n","camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n","\n","display(image)\n","\n","#카메라 인스턴스 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXtCoO1w1w_z"},"outputs":[],"source":["import os\n","\n","red_dir = \"dataset/red\"\n","green_dir = \"dataset/green\"\n","blue_dir = \"dataset/blue\"\n","\n","# 디렉토리가 이미 존재하는 경우 다음 함수가 오류를 발생시킬 수 있기 때문에 \"try/except\" 문을 사용.\n","try:\n","    os.makedirs(red_dir)\n","    os.makedirs(green_dir)\n","    os.makedirs(blue_dir)\n","except FileExistsError:\n","    print('Directories not created becasue they already exist')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--RTjeTb1w_z"},"outputs":[],"source":["button_layout =  widgets.Layout(width='128px',height='64px')\n","\n","red_button = weigets.Button(description='add RED',button_style='success',layout=button_layout)\n","red_button.style.button_color = 'red'\n","\n","blue_button = weigets.Button(description='add BLUE',button_style='success',layout=button_layout)\n","blue_button.style.button_color = blue'\n","\n","green_button = weigets.Button(description='add GREEN',button_style='success',layout=button_layout)\n","green_button.style.button_color = 'green'\n","\n","red_count = widgets.IntText(layout=button_layout,value=len(os.listdir(red_dir)))\n","blue_count = widgets.IntText(layout=button_layout,value=len(os.listdir(blue_dir)))\n","green_count = widgets.IntText(layout=button_layout,value=len(os.listdir(green_dir)))\n","\n","display(widgets.HBox([red_count, red_button]))\n","display(widgets.HBox([blue_count, blue_button]))\n","display(widgets.HBox([green_count, green_button]))\n","# 각 사진을 저장할 수 있는 버튼과, 사진의 수량을 보여줄 텍스트 박스를 추가함."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqfgXpTU1w_0"},"outputs":[],"source":["from uuid import uuid1\n","\n","def save_snapshot(directory):\n","    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n","    with open(image_path, 'wb') as f:\n","        f.write(image.value)\n","\n","def save_blue():\n","    global blue_dir, blue_count\n","    save_snapshot(blue_dir)\n","    free_count.value = len(os.listdir(blue_dir))\n","\n","def save_red():\n","    global red_dir, red_count\n","    save_snapshot(red_dir)\n","    free_count.value = len(os.listdir(red_dir))\n","\n","def save_green():\n","    global green_dir, green_count\n","    save_snapshot(green_dir)\n","    free_count.value = len(os.listdir(green_dir))\n","\n","\n","blue_button.on_click(lamda x: save_blue())\n","red_button.on_click(lamda x: save_red())\n","green_button.on_click(lamda x: save_grren())\n","\n","#각 버튼 기능에 맞는 사진 저장 함수. on_Click이벤트에 등록.\n","#즉, 버튼 누르면 저장됨."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FnrDHRS1w_0"},"outputs":[],"source":["display(image)\n","display(widgets.HBox([red_count, red_button]))\n","display(widgets.HBox([blue_count, blue_button]))\n","display(widgets.HBox([green_count, green_button]))\n","\n","#카메라 보여주기--> 버튼 누르면, add photo 됨."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_641_We1w_0"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","dataset = datasets.ImageFolder(\n","    'dataset',\n","    transforms.Compose([\n","        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mr3Mb0xL1w_0"},"outputs":[],"source":["train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 10, 10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSBRzn1Y1w_1"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1SBTYoV71w_1"},"outputs":[],"source":["model = models.alexnet(pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3TG_AOH1w_1"},"outputs":[],"source":["model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gq9oMdHg1w_1"},"outputs":[],"source":["device = torch.device('cuda')\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waPYlQ9L1w_2"},"outputs":[],"source":["NUM_EPOCHS = 30\n","BEST_MODEL_PATH = 'best_model.pth'\n","best_accuracy = 0.0\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","for epoch in range(NUM_EPOCHS):\n","\n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.cross_entropy(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    test_error_count = 0.0\n","    for images, labels in iter(test_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n","\n","    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n","    print('%d: %f' % (epoch, test_accuracy))\n","    if test_accuracy > best_accuracy:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_accuracy = test_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZV6pTndm1w_2"},"outputs":[],"source":["import torch\n","import torchvision\n","\n","model = torchvision.models.alexnet(pretrained=False)\n","model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HNYwmbe1w_2"},"outputs":[],"source":["model.load_state_dict(torch.load('best_model.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phinUoTd1w_2"},"outputs":[],"source":["device = torch.device('cuda')\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6_E11Ue1w_2"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","mean = 255.0 * np.array([0.485, 0.456, 0.406])\n","stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n","\n","normalize = torchvision.transforms.Normalize(mean, stdev)\n","\n","def preprocess(camera_value):\n","    global device, normalize\n","    x = camera_value\n","    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n","    x = x.transpose((2, 0, 1))\n","    x = torch.from_numpy(x).float()\n","    x = normalize(x)\n","    x = x.to(device)\n","    x = x[None, ...]\n","    return x"]},{"cell_type":"markdown","source":["실행"],"metadata":{"id":"kGIvC0GaQ10L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCGpQBJl1w_3"},"outputs":[],"source":["import traitlets\n","from IPython.display import display\n","import ipywidgets.widgets as widgets\n","from jetbot import Camera, bgr8_to_jpeg\n","\n","camera = Camera.instance(width=224, height=224,fps=10)\n","image = widgets.Image(format='jpeg', width=224, height=224)\n","\n","blue_slider = widgets.FloatSlider(description='blue', min=0.0, max=1.0, orientation='vertical')\n","red_slider = widgets.FloatSlider(description='red', min=0.0, max=1.0, orientation='vertical')\n","green_slider = widgets.FloatSlider(description='green', min=0.0, max=1.0, orientation='vertical')\n","\n","camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n","\n","display(widgets.HBox([image, blocked_slider]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRvA9qP_1w_3"},"outputs":[],"source":["from jetbot import Robot\n","import time\n","\n","robot = Robot()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvGZA0_71w_3"},"outputs":[],"source":["import torch.nn.functional as F\n","import time\n","\n","def update(change):\n","    global blocked_slider, robot\n","    x = change['new']\n","    x = preprocess(x)\n","    y = model(x)\n","\n","    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n","    y = F.softmax(y, dim=1)\n","    prob_blue = float(y.flatten([2]))\n","    prob_red = float(y.flatten()[1])\n","    prob_green = float(y.flatten()[0])\n","\n","    if prob_blue < 0.6:\n","        robot.forward(0.6)\n","        time.sleep(1)\n","        robot.stop()\n","    elif prob_red < 0.6:\n","        robot.forward(0.2)\n","        time.sleep(1)\n","        robot.stop()\n","    else:\n","        robot.forward(0.4)\n","        time.sleep(1)\n","        robot.stop()\n","\n","update({'new': camera.value})  # we call the function once to intialize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsddEjAv1w_3"},"outputs":[],"source":["camera.observe(update, names='value')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_3lYU9n1w_3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ciytC27z1w_3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyC3kg881w_3"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}